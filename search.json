[
  {
    "objectID": "mix-gaussians.html",
    "href": "mix-gaussians.html",
    "title": "mix-gaussians",
    "section": "",
    "text": "import matplotlib.pyplot as plt\nimport seaborn as sns\nimport torch\n\n\n# Gaussian Parameters\ntorch.manual_seed(1442)\nn_guassians = 25\nmu = torch.randn(n_guassians)\nsigma = torch.randn(n_guassians) ** 2 # This should probably have different params\nweights = torch.rand(n_guassians)\nweights /= weights.sum()\n\n\ndef sample():\n    return torch.normal(mu, sigma)[torch.multinomial(weights, 1).item()]\n\n\nn_samples = 10000\nsamples = torch.tensor([sample() for _ in range(n_samples)])\n\n\n_ = sns.kdeplot(samples.numpy())",
    "crumbs": [
      "mix-gaussians"
    ]
  },
  {
    "objectID": "vae.html",
    "href": "vae.html",
    "title": "vae",
    "section": "",
    "text": "import os\n\n\nimport lightning as pl\n\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\n\nimport numpy as np\n\nimport torch\nimport torch.nn as nn\nimport torchvision.transforms as transforms\n\nfrom torchvision.datasets import MNIST\n\n\n# Download datasets\nds_path = os.path.abspath(\"datasets\")\nos.makedirs(ds_path, exist_ok=True)\n\n\nclass MNISTDataModule(pl.LightningDataModule):\n    def __init__(self, ds_path: str, batch_size=32, random_seed=42):\n        super().__init__()\n        self.ds_path = ds_path\n        self.batch_size = batch_size\n        self.random_seed = random_seed\n\n    def prepare_data(self):\n        # Download datasets\n        transform = transforms.Compose([transforms.ToTensor()])\n\n        self.orig_train_dataset = MNIST(self.ds_path, transform=transform, download=True, train=True)\n        self.test_dataset  = MNIST(self.ds_path, transform=transform, download=True, train=False)\n\n    def setup(self, stage=None):\n        # Assign train/val datasets for use in dataloaders\n        total_size = len(self.orig_train_dataset)\n        train_size = int(0.9 * total_size)\n        val_size = total_size - train_size\n\n        gen = torch.Generator()\n        gen.manual_seed(self.random_seed)\n        if stage == 'fit' or stage is None:\n            self.train_dataset, self.val_dataset = torch.utils.data.random_split(self.orig_train_dataset, [train_size, val_size], generator=gen)\n\n    def train_dataloader(self):\n        return torch.utils.data.DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True)\n\n    def val_dataloader(self):\n        return torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size)\n\n    def test_dataloader(self):\n        return torch.utils.data.DataLoader(self.test_dataset, batch_size=self.batch_size)\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\nUsing device: cpu\n\n\n\ndm = MNISTDataModule(ds_path, batch_size=32)\ndm.prepare_data()\ndm.setup()\n\n\ntrain_loader = dm.train_dataloader()\nbatch = next(iter(train_loader))\n\n\nbatch[0].shape, batch[1].shape\n\n(torch.Size([32, 1, 28, 28]), torch.Size([32]))\n\n\n\nnum_samples = 25\nbatch_images = batch[0]\nsample_images = batch_images[:num_samples, 0]\n\nfig = plt.figure(figsize=(5, 5))\ngrid = ImageGrid(fig, 111, nrows_ncols=(5, 5), axes_pad=0.1)\n\nfor ax, im in zip(grid, sample_images):\n    ax.imshow(im, cmap='gray')\n    ax.axis('off')\n\nplt.show()\n\n\n\n\n\n\n\n\n\nclass VAE(nn.Module):\n    def __init__(self, input_dim=784, hidden_dim=400, latent_dim=200):\n        super(VAE, self).__init__()\n\n        # encoder\n        self.encoder = nn.Sequential(\n            nn.Linear(input_dim, hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_dim, latent_dim),\n            nn.LeakyReLU(0.2)\n        )\n\n        # latent mean and variance\n        self.mean_layer = nn.Linear(latent_dim, 2)\n        self.logvar_layer = nn.Linear(latent_dim, 2)\n\n        # decoder\n        self.decoder = nn.Sequential(\n            nn.Linear(2, latent_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(latent_dim, hidden_dim),\n            nn.LeakyReLU(0.2),\n            nn.Linear(hidden_dim, input_dim),\n            nn.Sigmoid()\n        )\n\n    def encode(self, x):\n        x = self.encoder(x)\n        mean, logvar = self.mean_layer(x), self.logvar_layer(x)\n        return mean, logvar\n\n    def reparameterization(self, mean, var):\n        epsilon = torch.randn_like(var).to(mean)\n        z = mean + var*epsilon\n        return z\n\n    def decode(self, x):\n        return self.decoder(x)\n\n    def forward(self, x):\n        mean, log_var = self.encode(x)\n        z = self.reparameterization(mean, torch.exp(0.5 * log_var))\n        x_hat = self.decode(z)\n        return x_hat, mean, log_var\n\n\nclass VAEModule(pl.LightningModule):\n    def __init__(self, model: VAE, lr: float = 1e-3):\n        super().__init__()\n        self.model = model\n        self.lr = lr\n\n        self.loss = nn.BCELoss(reduction='sum')\n\n    def forward(self, x):\n        return self.model(x)\n\n    def shared_step(self, batch):\n        x, _ = batch\n        x = x.view(x.size(0), -1)\n        x_hat, mean, log_var = self(x)\n\n        recon_loss = self.loss(x_hat, x)\n        kl_div = -0.5 * torch.sum(1 + log_var - mean.pow(2) - log_var.exp())\n\n        loss = recon_loss + kl_div\n        return loss\n\n    def training_step(self, batch, batch_idx):\n        loss = self.shared_step(batch)\n        self.log('train_loss', loss)\n        return loss\n\n    def validation_step(self, batch, batch_idx):\n        loss = self.shared_step(batch)\n        self.log('val_loss', loss)\n        return loss\n\n    def test_step(self, batch, batch_idx):\n        loss = self.shared_step(batch)\n        self.log('test_loss', loss)\n        return loss\n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=self.lr)\n        return optimizer\n\n\n# Train model\nmodel = VAE()\nvae = VAEModule(model)\n\ntrainer = pl.Trainer(max_epochs=10)\ntrainer.fit(vae, dm)\n\nGPU available: True (mps), used: True\nTPU available: False, using: 0 TPU cores\nIPU available: False, using: 0 IPUs\nHPU available: False, using: 0 HPUs\n\n  | Name  | Type    | Params\n----------------------------------\n0 | model | VAE     | 790 K \n1 | loss  | BCELoss | 0     \n----------------------------------\n790 K     Trainable params\n0         Non-trainable params\n790 K     Total params\n3.162     Total estimated model params size (MB)\n/Users/spather/code/ai-learning/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n/Users/spather/code/ai-learning/venv/lib/python3.11/site-packages/lightning/pytorch/trainer/connectors/data_connector.py:441: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=15` in the `DataLoader` to improve performance.\n`Trainer.fit` stopped: `max_epochs=10` reached.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef generate_digit(mean, var):\n    z_sample = vae.model.reparameterization(mean, var).unsqueeze(0).to(vae.device)\n    x_decoded = vae.model.decode(z_sample)\n    digit = x_decoded.detach().cpu().reshape(28, 28) # reshape vector to 2d array\n    plt.title(f'[{mean},{var}]')\n    plt.imshow(digit, cmap='gray')\n    plt.axis('off')\n    plt.show()\n\n\ntorch.manual_seed(42)\ngenerate_digit(torch.tensor([0.0, 1.0]), torch.tensor([0.3, 0.3])),\ngenerate_digit(torch.tensor([1.0, 0.0]), torch.tensor([0.3, 0.3]))\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef plot_latent_space(model, device: str, scale=5.0, n=25, digit_size=28, figsize=15):\n    # display a n*n 2D manifold of digits\n    figure = np.zeros((digit_size * n, digit_size * n))\n\n    # construct a grid\n    grid_x = np.linspace(-scale, scale, n)\n    grid_y = np.linspace(-scale, scale, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = torch.tensor([[xi, yi]], dtype=torch.float).to(device)\n            x_decoded = model.decode(z_sample)\n            digit = x_decoded[0].detach().cpu().reshape(digit_size, digit_size)\n            figure[i * digit_size : (i + 1) * digit_size, j * digit_size : (j + 1) * digit_size,] = digit\n\n    plt.figure(figsize=(figsize, figsize))\n    plt.title('VAE Latent Space Visualization')\n    start_range = digit_size // 2\n    end_range = n * digit_size + start_range\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"mean, z [0]\")\n    plt.ylabel(\"var, z [1]\")\n    plt.imshow(figure, cmap=\"Greys_r\")\n    plt.show()\n\n\nplot_latent_space(vae.model, vae.device, scale=5.0, n=25, digit_size=28, figsize=15)",
    "crumbs": [
      "vae"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ai-learning",
    "section": "",
    "text": "For now nbs/ just contains some exploratory notebooks.",
    "crumbs": [
      "ai-learning"
    ]
  }
]